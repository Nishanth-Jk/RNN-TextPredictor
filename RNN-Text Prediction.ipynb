{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text has 581881 characters\n"
     ]
    }
   ],
   "source": [
    "# read in the text, transforming everything to lower case\n",
    "text = open('datasets/holmes.txt').read().lower()\n",
    "print('original text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ï»¿project gutenberg's the adventures of sherlock holmes, by arthur conan doyle\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.net\\n\\n\\ntitle: the adventures of sherlock holmes\\n\\nauthor: arthur conan doyle\\n\\nposting date: april 18, 2011 [ebook #1661]\\nfirst posted: november 29, 2002\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook the adventures of sherlock holmes ***\\n\\n\\n\\n\\nproduced by an anonymous project gutenberg volunteer and jose menendez\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nthe adventures of sherlock holmes\\n\\nby\\n\\nsir arthur conan doyle\\n\\n\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a di\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing symbols\n",
    "text = text[1302:]\n",
    "text = text.replace('\\n',' ')    # replacing '\\n' with '' simply removes the sequence\n",
    "text = text.replace('\\r',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer--excellent for drawing the veil from men's motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "allowed_chars = string.ascii_lowercase + ' ' + '!' + ',' + '.' + ':' + ';' + '?'\n",
    "\n",
    "# remove as many non-english characters and character sequences as you can \n",
    "for char in text:\n",
    "    if char not in allowed_chars:\n",
    "        text = text.replace(char, ' ')\n",
    "\n",
    "# shorten any extra dead space created above\n",
    "text = text.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer excellent for drawing the veil from men s motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene a'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of characters 573688\n",
      "unique characters= 33\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print (\"total number of characters \" +  str(len(text)) )\n",
    "print (\"unique characters= \" +  str(len(chars)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are using sliding windows concept here\n",
    "def window_transform_text(text,window_size,step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    ctr = 0\n",
    "    \n",
    "    # Goes from window_size until the end, and pick previous characters\n",
    "    for i in range(window_size, len(text), step_size):\n",
    "        inputs.append(text[ctr:i])\n",
    "        outputs.append(text[i])\n",
    "        ctr = ctr + step_size\n",
    "    \n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "step_size = 5\n",
    "inputs, outputs = window_transform_text(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique characters are\n",
      "[' ', '!', ',', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(\"unique characters are\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " ',': 2,\n",
       " '.': 3,\n",
       " ':': 4,\n",
       " ';': 5,\n",
       " '?': 6,\n",
       " 'a': 7,\n",
       " 'b': 8,\n",
       " 'c': 9,\n",
       " 'd': 10,\n",
       " 'e': 11,\n",
       " 'f': 12,\n",
       " 'g': 13,\n",
       " 'h': 14,\n",
       " 'i': 15,\n",
       " 'j': 16,\n",
       " 'k': 17,\n",
       " 'l': 18,\n",
       " 'm': 19,\n",
       " 'n': 20,\n",
       " 'o': 21,\n",
       " 'p': 22,\n",
       " 'q': 23,\n",
       " 'r': 24,\n",
       " 's': 25,\n",
       " 't': 26,\n",
       " 'u': 27,\n",
       " 'v': 28,\n",
       " 'w': 29,\n",
       " 'x': 30,\n",
       " 'y': 31,\n",
       " 'z': 32}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical numbers\n",
    "def encode_io_pairs(text,window_size,step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "step_size = 5\n",
    "X,y = encode_io_pairs(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "#from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from tensorflow.keras import optimizers\n",
    "#import keras\n",
    "import random\n",
    "\n",
    "# TODO build the required RNN model: a single LSTM hidden layer with softmax activation, categorical_crossentropy loss \n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(window_size, 33)))\n",
    "model.add(Dense(33, activation='softmax'))\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsmall = X[:10000,:,:]\n",
    "ysmall = y[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "20/20 [==============================] - 37s 2s/step - loss: 3.0314\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 32s 2s/step - loss: 2.8881\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 32s 2s/step - loss: 2.8604\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 21s 1s/step - loss: 2.8283\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 19s 934ms/step - loss: 2.7908\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 19s 943ms/step - loss: 2.7298\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 19s 950ms/step - loss: 2.6667\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 19s 952ms/step - loss: 2.6100\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 19s 945ms/step - loss: 2.5537\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 19s 945ms/step - loss: 2.5044\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 19s 954ms/step - loss: 2.4647\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 19s 953ms/step - loss: 2.4276\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 20s 978ms/step - loss: 2.3933\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 19s 975ms/step - loss: 2.3635\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 19s 960ms/step - loss: 2.3414\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 19s 948ms/step - loss: 2.3200\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 19s 956ms/step - loss: 2.2943\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 19s 957ms/step - loss: 2.2681\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 19s 949ms/step - loss: 2.2518\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 19s 952ms/step - loss: 2.2353\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 19s 962ms/step - loss: 2.2160\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 19s 954ms/step - loss: 2.1938\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 19s 964ms/step - loss: 2.1832\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 19s 954ms/step - loss: 2.1570\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 19s 962ms/step - loss: 2.1422\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 19s 950ms/step - loss: 2.1269\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 19s 949ms/step - loss: 2.1039\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 19s 953ms/step - loss: 2.0932\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 19s 961ms/step - loss: 2.0757\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 19s 972ms/step - loss: 2.0566\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 20s 977ms/step - loss: 2.0342\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 19s 963ms/step - loss: 2.0215\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 19s 948ms/step - loss: 2.0027\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 19s 956ms/step - loss: 1.9787\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 19s 971ms/step - loss: 1.9661\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 19s 965ms/step - loss: 1.9466\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 20s 1s/step - loss: 1.9203\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 21s 1s/step - loss: 1.9079\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 20s 1s/step - loss: 1.8861\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 20s 992ms/step - loss: 1.8631\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(Xsmall, ysmall, batch_size=500, epochs=40,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_small_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses trained model to predict a desired number of future characters\n",
    "def predict_next_chars(model,input_chars,num_to_predict):     \n",
    "    # create output\n",
    "    predicted_chars = ''\n",
    "    for i in range(num_to_predict):\n",
    "        # convert this round's predicted characters to numerical input    \n",
    "        x_test = np.zeros((1, window_size, len(chars)))\n",
    "        for t, char in enumerate(input_chars):\n",
    "            x_test[0, t, chars_to_indices[char]] = 1.\n",
    "\n",
    "        # make this round's prediction\n",
    "        test_predict = model.predict(x_test,verbose = 0)[0]\n",
    "\n",
    "        # translate numerical prediction back to characters\n",
    "        r = np.argmax(test_predict)                           # predict class of each test input\n",
    "        d = indices_to_chars[r] \n",
    "\n",
    "        # update predicted_chars and input\n",
    "        predicted_chars+=d\n",
    "        input_chars+=d\n",
    "        input_chars = input_chars[1:]\n",
    "    return predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      " his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion ak\"\n",
      "\n",
      "predicted chars = \n",
      " of the cout in the couthe soull and betton the southe sout and he sout in the couthe soull an the t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "rver excellent for drawing the veil from men s motives and actions. but for the trained reasoner to \"\n",
      "\n",
      "predicted chars = \n",
      "he cout the the the mare and whith a sould and herise to the the the was he soull and the couthe sou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "dler, of dubious and questionable memory. i had seen little of holmes lately. my marriage had drifte\"\n",
      "\n",
      "predicted chars = \n",
      "d on the couthe southe sout and her inderome the coust and he was the there in the mast of the couth\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_inds = [0, 500, 1000]\n",
    "\n",
    "# load in weights\n",
    "model.load_weights('model_weights/best_RNN_small_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    print('------------------')\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - 205s 1s/step - loss: 2.0326\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 203s 1s/step - loss: 1.9475\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 195s 975ms/step - loss: 1.8846\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 193s 965ms/step - loss: 1.8310\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 195s 973ms/step - loss: 1.7851\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 201s 1s/step - loss: 1.7424\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 204s 1s/step - loss: 1.7041\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 205s 1s/step - loss: 1.6680\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 206s 1s/step - loss: 1.6342\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.6022\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 210s 1s/step - loss: 1.5721\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 213s 1s/step - loss: 1.5415\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 210s 1s/step - loss: 1.5133\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.4845\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.4584\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.4293\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 208s 1s/step - loss: 1.4031\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.3761\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 209s 1s/step - loss: 1.3497\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.3240\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 208s 1s/step - loss: 1.2965\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.2704\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 206s 1s/step - loss: 1.2441\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.2174\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 206s 1s/step - loss: 1.1918\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 208s 1s/step - loss: 1.1667\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 208s 1s/step - loss: 1.1406\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 211s 1s/step - loss: 1.1157\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 207s 1s/step - loss: 1.0905\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 209s 1s/step - loss: 1.0650\n"
     ]
    }
   ],
   "source": [
    "Xlarge = X[:100000,:,:]\n",
    "ylarge = y[:100000,:]\n",
    "\n",
    "# TODO: fit to our larger dataset\n",
    "model.fit(Xlarge, ylarge, batch_size=500, epochs=30,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_large_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      " his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion ak\"\n",
      "\n",
      "predicted chars = \n",
      "ing to his eyes with a little street which i sen the lany of the windows and for the read in the str\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "rver excellent for drawing the veil from men s motives and actions. but for the trained reasoner to \"\n",
      "\n",
      "predicted chars = \n",
      "arvestered with a recume court of and of the glinds as if the past the street, and i shall be the fa\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "dler, of dubious and questionable memory. i had seen little of holmes lately. my marriage had drifte\"\n",
      "\n",
      "predicted chars = \n",
      "d to sut is my off comp.  it is a sigat of cayse and some to think that the came hadd an ond of the \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_inds = [0, 500, 1000]\n",
    "\n",
    "# save output\n",
    "f = open('text_gen_output/RNN_large_textdata_output.txt', 'w')  # create an output file to write too\n",
    "\n",
    "# load weights\n",
    "model.load_weights('model_weights/best_RNN_large_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    line = '-------------------' + '\\n'\n",
    "    print(line)\n",
    "    f.write(line)\n",
    "\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "    f.write(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    predict_line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(predict_line)\n",
    "    f.write(predict_line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
